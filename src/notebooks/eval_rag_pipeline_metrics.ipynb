{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7468c8bf",
   "metadata": {},
   "source": [
    "# RAG Pipeline A/B Evaluation (Model-only)\n",
    "\n",
    "This notebook loads your project and evaluates the **LLM-only** behavior of `rag.pipeline.RAGPipeline.answer` for a fixed set of queries, comparing two Ollama models (A/B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbab84cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sinedo/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#OpenBLAS Warning : Detect OpenMP Loop and this application may hang...\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"GOTO_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "# silence HF advisory warnings & progress bars\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from transformers.utils import logging as hf_logging\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "# (optional) quiet sentence-transformers too\n",
    "import logging\n",
    "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc9841",
   "metadata": {},
   "source": [
    "# RAG ENV VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7cd61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def init_env_defaults() -> None:\n",
    "    s = os.environ.setdefault\n",
    "    nproc = str(os.cpu_count() or 8)\n",
    "    # ---- defaults (override via env) ----\n",
    "    \n",
    "    s(\"RAG_ART_INDEX_PATH\", \"src/st3405_data/index/st4305_text_bgem3.faiss\")\n",
    "    s(\"RAG_ART_STORE_PATH\", \"src/st3405_data/index/st4305_store.pkl.gz\")\n",
    "    s(\"RAG_CTX_BUDGET_CHARS\", \"10000\")\n",
    "    \n",
    "    s(\"RAG_HYBRID_ALPHA\", \"0.5\")      # weight for dense in fusion (0..1)\n",
    "    s(\"RAG_QUERY_EXPAND\", \"1\")        # 1=enable LLM query reformulation via Ollama\n",
    "    s(\"RAG_QUERY_EXPAND_K\", \"0.5\")    # keep as in script\n",
    "    s(\"RAG_PRF_ENABLE\", \"1\")\n",
    "    s(\"RAG_PRF_TERMS\", \"8\")\n",
    "    #\n",
    "    # s(\"RAG_OLLAMA_MODEL\", \"llama3:latest\")\n",
    "    s(\"RAG_OLLAMA_MODEL\", \"llama3.2:3b\")\n",
    "    s(\"RAG_RERANK_TIMEOUT\", \"15.0\")\n",
    "    s(\"RAG_SELECT_TIMEOUT\", \"10.0\")\n",
    "    s(\"RAG_QUERY_VARIATIONS\", \"10\")\n",
    "\n",
    "    s(\"RAG_OLLAMA_NUM_PREDICT\", \"512\")\n",
    "\n",
    "    s(\"RAG_MIN_CTX\", \"2\")\n",
    "    s(\"RAG_MAX_CTX\", \"3\")\n",
    "\n",
    "    s(\"RAG_CANDIDATE_K_FOR_RERANK\", \"10\")\n",
    "    s(\"RAG_FINAL_TOP_N\", \"3\")\n",
    "\n",
    "    s(\"RAG_DISABLE_SELECT\", \"1\")\n",
    "\n",
    "    # Models / batching\n",
    "    \n",
    "    s(\"RAG_EMBEDDER_MODEL\", \"BAAI/bge-m3\")\n",
    "    s(\"RAG_EMBED_DEVICE\", \"cpu\")\n",
    "    s(\"RAG_EMBED_BATCH\", \"1\")    \n",
    "    s(\"RAG_EMBED_MAX_LENGTH\", \"256\")\n",
    "\n",
    "    #\"BAAI/bge-reranker-base\"\n",
    "    # or jinaai/jina-reranker-v2-base-multilingual\n",
    "    #naver/xprovence-reranker-bgem3-v1\n",
    "    #naver/provence-reranker-debertav3-v1\n",
    "    s(\"RAG_RERANKER_MODEL\", \"BAAI/bge-reranker-base\")  \n",
    "    \n",
    "    # s(\"RAG_RERANKER_DEVICE\", \"cuda\")\n",
    "    # s(\"RAG_RERANKER_WINDOW\", \"384\")\n",
    "    # s(\"RAG_RERANKER_STRIDE\", \"256\")\n",
    "    # s(\"RAG_RERANKER_FP16\", \"1\")\n",
    "    # s(\"RAG_RERANKER_PAD_MAX\", \"0\")\n",
    "    # s(\"RAG_RERANKER_WINDOW_BATCH\", \"1\")\n",
    "\n",
    "    #cpu\n",
    "    s(\"RAG_RERANKER_DEVICE\", \"cpu\")\n",
    "    s(\"RAG_RERANKER_WINDOW\", \"384\")\n",
    "    s(\"RAG_RERANKER_STRIDE\", \"256\")\n",
    "    s(\"RAG_RERANKER_FP16\", \"0\")\n",
    "    s(\"RAG_RERANKER_WINDOW_BATCH\", \"8\")    \n",
    "    s(\"RAG_RERANKER_QUANTIZE\", \"1\")      \n",
    "    s(\"TOKENIZERS_PARALLELISM\", \"true\")    \n",
    "    s(\"OMP_NUM_THREADS\", nproc)\n",
    "    s(\"MKL_NUM_THREADS\", os.environ.get(\"OMP_NUM_THREADS\", nproc))\n",
    "    s(\"OPENBLAS_NUM_THREADS\", os.environ.get(\"OMP_NUM_THREADS\", nproc))\n",
    "    s(\"NUMEXPR_NUM_THREADS\", os.environ.get(\"OMP_NUM_THREADS\", nproc))\n",
    "\n",
    "    s(\"RAG_RERANKER_MAX_LEN\", \"384\")\n",
    "    s(\"RAG_RERANKER_AGG\", \"max\")    \n",
    "\n",
    "    s(\"RAG_DISABLE_RERANK\", \"1\")\n",
    "    s(\"RAG_MAX_VARIANTS\", \"4\")\n",
    "\n",
    "    # Timeouts / perf\n",
    "    s(\"RAG_EXPAND_TIMEOUT\", \"10.0\")\n",
    "    s(\"RAG_BM25_PARALLEL\", \"1\")\n",
    "    s(\"RAG_BM25_WORKERS\", \"16\")\n",
    "\n",
    "    s(\"RAG_DENSE_K_PER_QUERY\", \"10\")\n",
    "    s(\"RAG_SPARSE_K_PER_QUERY\", \"10\")\n",
    "    s(\"RAG_ENV_DUMPED\", \"0\")\n",
    "    s(\"RAG_FAISS_GPU\", \"0\")\n",
    "\n",
    "    # CUDA allocator\n",
    "    s(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "    s(\"CUDA_VISIBLE_DEVICES\", \"1\")\n",
    "    \n",
    "    s(\"KMP_AFFINITY\", \"granularity=fine,compact,1,0\")\n",
    "\n",
    "    try:\n",
    "        import torch\n",
    "        torch.set_grad_enabled(False)\n",
    "        torch.set_num_threads(int(os.environ[\"OMP_NUM_THREADS\"]))\n",
    "        torch.set_num_interop_threads(1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "# Chame no startup da sua app:\n",
    "init_env_defaults()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b1b0230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project at: /mnt/dados/projetos/gps-tracking-rag-assistent-v1/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def get_root_path():\n",
    "    \"\"\"Always use the same, absolute (relative to root) paths\n",
    "\n",
    "    which makes moving the notebooks around easier.\n",
    "    \"\"\"\n",
    "    return Path(os.getcwd()).parent\n",
    "\n",
    "PROJECT_DIR = Path(get_root_path())\n",
    "assert PROJECT_DIR.exists(), PROJECT_DIR\n",
    "\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "\n",
    "print(\"Using project at:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2cdb5",
   "metadata": {},
   "source": [
    "# Avalia√ß√£o do RagPipeline com Conjunto de Perguntas (Homologa√ß√£o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab741a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>query</th>\n",
       "      <th>answer</th>\n",
       "      <th>gold_doc_ids</th>\n",
       "      <th>gold_refs_hint</th>\n",
       "      <th>section_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q01</td>\n",
       "      <td>Comandos/Par√¢metros</td>\n",
       "      <td>Qual o comando para reiniciar o dispositivo vi...</td>\n",
       "      <td>Use o comando 'Reboot' (reinicia o dispositivo).</td>\n",
       "      <td>[20.envio de comandos]</td>\n",
       "      <td>[20. ENVIO DE COMANDOS ‚Äî Comando Reboot.]</td>\n",
       "      <td>20.envio de comandos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q02</td>\n",
       "      <td>Comandos/Par√¢metros</td>\n",
       "      <td>Qual o comando para habilitar a Sa√≠da 1?</td>\n",
       "      <td>Use o comando 'Enable1' (ativa a Sa√≠da 1).</td>\n",
       "      <td>[20.envio de comandos]</td>\n",
       "      <td>[20. ENVIO DE COMANDOS ‚Äî Enable1 / Disable1.]</td>\n",
       "      <td>20.envio de comandos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q03</td>\n",
       "      <td>Comandos/Par√¢metros</td>\n",
       "      <td>Como consultar a vers√£o do firmware do rastrea...</td>\n",
       "      <td>Envie 'ReqVer' com Option=1 para solicitar a v...</td>\n",
       "      <td>[20.envio de comandos]</td>\n",
       "      <td>[20. ENVIO DE COMANDOS ‚Äî ReqVer (Option=1).]</td>\n",
       "      <td>20.envio de comandos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q04</td>\n",
       "      <td>Comandos/Par√¢metros</td>\n",
       "      <td>Como iniciar a calibra√ß√£o DPA por comando?</td>\n",
       "      <td>Use 'Start DPA Calibration' para iniciar e 'St...</td>\n",
       "      <td>[20.envio de comandos]</td>\n",
       "      <td>[20. ENVIO DE COMANDOS ‚Äî Comandos de calibra√ß√£...</td>\n",
       "      <td>20.envio de comandos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q05</td>\n",
       "      <td>Comandos/Par√¢metros</td>\n",
       "      <td>Existe comando para consultar o status do anti...</td>\n",
       "      <td>Sim. Utilize 'Get anti theft status' para cons...</td>\n",
       "      <td>[20.envio de comandos]</td>\n",
       "      <td>[20. ENVIO DE COMANDOS ‚Äî Consulta antifurto.]</td>\n",
       "      <td>20.envio de comandos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q06</td>\n",
       "      <td>Configura√ß√µes de interface</td>\n",
       "      <td>Como habilitar o Fine Tracking no ST4305?</td>\n",
       "      <td>Par√¢metro (3010) ‚Äî Habilitar Fine Tracking: 01...</td>\n",
       "      <td>[27.configurando fine tracking]</td>\n",
       "      <td>[27. CONFIGURANDO FINE TRACKING ‚Äî (3010) Habil...</td>\n",
       "      <td>27.configurando fine tracking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q07</td>\n",
       "      <td>Configura√ß√µes de interface</td>\n",
       "      <td>Qual par√¢metro define o intervalo entre posi√ß√µ...</td>\n",
       "      <td>Par√¢metro (3011) ‚Äî Intervalo de posi√ß√µes GPS e...</td>\n",
       "      <td>[27.configurando fine tracking]</td>\n",
       "      <td>[27. CONFIGURANDO FINE TRACKING ‚Äî (3011) Inter...</td>\n",
       "      <td>27.configurando fine tracking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q08</td>\n",
       "      <td>Configura√ß√µes de interface</td>\n",
       "      <td>Como definir a quantidade de posi√ß√µes enviadas...</td>\n",
       "      <td>Par√¢metro (3012) ‚Äî Quantidade de posi√ß√µes por ...</td>\n",
       "      <td>[27.configurando fine tracking]</td>\n",
       "      <td>[27. CONFIGURANDO FINE TRACKING ‚Äî (3012) Quant...</td>\n",
       "      <td>27.configurando fine tracking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q09</td>\n",
       "      <td>Configura√ß√µes de interface</td>\n",
       "      <td>Quais campos podem ser habilitados no cabe√ßalh...</td>\n",
       "      <td>No modo Small Table, √© poss√≠vel habilitar camp...</td>\n",
       "      <td>[24.configura√ß√£o de cabe√ßalhos (stt e alt)]</td>\n",
       "      <td>[24. CONFIGURA√á√ÉO DE CABE√áALHOS (STT E ALT) ‚Äî ...</td>\n",
       "      <td>24.configura√ß√£o de cabe√ßalhos (stt e alt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q10</td>\n",
       "      <td>Configura√ß√µes de interface</td>\n",
       "      <td>Como configurar a APN de dados (par√¢metros de ...</td>\n",
       "      <td>Na se√ß√£o de Par√¢metro de Rede, configure APN, ...</td>\n",
       "      <td>[7.par√¢metro de rede]</td>\n",
       "      <td>[7. PAR√ÇMETRO DE REDE ‚Äî APN/dados m√≥veis.]</td>\n",
       "      <td>7.par√¢metro de rede</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                    category  \\\n",
       "0  Q01         Comandos/Par√¢metros   \n",
       "1  Q02         Comandos/Par√¢metros   \n",
       "2  Q03         Comandos/Par√¢metros   \n",
       "3  Q04         Comandos/Par√¢metros   \n",
       "4  Q05         Comandos/Par√¢metros   \n",
       "5  Q06  Configura√ß√µes de interface   \n",
       "6  Q07  Configura√ß√µes de interface   \n",
       "7  Q08  Configura√ß√µes de interface   \n",
       "8  Q09  Configura√ß√µes de interface   \n",
       "9  Q10  Configura√ß√µes de interface   \n",
       "\n",
       "                                               query  \\\n",
       "0  Qual o comando para reiniciar o dispositivo vi...   \n",
       "1           Qual o comando para habilitar a Sa√≠da 1?   \n",
       "2  Como consultar a vers√£o do firmware do rastrea...   \n",
       "3         Como iniciar a calibra√ß√£o DPA por comando?   \n",
       "4  Existe comando para consultar o status do anti...   \n",
       "5          Como habilitar o Fine Tracking no ST4305?   \n",
       "6  Qual par√¢metro define o intervalo entre posi√ß√µ...   \n",
       "7  Como definir a quantidade de posi√ß√µes enviadas...   \n",
       "8  Quais campos podem ser habilitados no cabe√ßalh...   \n",
       "9  Como configurar a APN de dados (par√¢metros de ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0   Use o comando 'Reboot' (reinicia o dispositivo).   \n",
       "1         Use o comando 'Enable1' (ativa a Sa√≠da 1).   \n",
       "2  Envie 'ReqVer' com Option=1 para solicitar a v...   \n",
       "3  Use 'Start DPA Calibration' para iniciar e 'St...   \n",
       "4  Sim. Utilize 'Get anti theft status' para cons...   \n",
       "5  Par√¢metro (3010) ‚Äî Habilitar Fine Tracking: 01...   \n",
       "6  Par√¢metro (3011) ‚Äî Intervalo de posi√ß√µes GPS e...   \n",
       "7  Par√¢metro (3012) ‚Äî Quantidade de posi√ß√µes por ...   \n",
       "8  No modo Small Table, √© poss√≠vel habilitar camp...   \n",
       "9  Na se√ß√£o de Par√¢metro de Rede, configure APN, ...   \n",
       "\n",
       "                                  gold_doc_ids  \\\n",
       "0                       [20.envio de comandos]   \n",
       "1                       [20.envio de comandos]   \n",
       "2                       [20.envio de comandos]   \n",
       "3                       [20.envio de comandos]   \n",
       "4                       [20.envio de comandos]   \n",
       "5              [27.configurando fine tracking]   \n",
       "6              [27.configurando fine tracking]   \n",
       "7              [27.configurando fine tracking]   \n",
       "8  [24.configura√ß√£o de cabe√ßalhos (stt e alt)]   \n",
       "9                        [7.par√¢metro de rede]   \n",
       "\n",
       "                                      gold_refs_hint  \\\n",
       "0          [20. ENVIO DE COMANDOS ‚Äî Comando Reboot.]   \n",
       "1      [20. ENVIO DE COMANDOS ‚Äî Enable1 / Disable1.]   \n",
       "2       [20. ENVIO DE COMANDOS ‚Äî ReqVer (Option=1).]   \n",
       "3  [20. ENVIO DE COMANDOS ‚Äî Comandos de calibra√ß√£...   \n",
       "4      [20. ENVIO DE COMANDOS ‚Äî Consulta antifurto.]   \n",
       "5  [27. CONFIGURANDO FINE TRACKING ‚Äî (3010) Habil...   \n",
       "6  [27. CONFIGURANDO FINE TRACKING ‚Äî (3011) Inter...   \n",
       "7  [27. CONFIGURANDO FINE TRACKING ‚Äî (3012) Quant...   \n",
       "8  [24. CONFIGURA√á√ÉO DE CABE√áALHOS (STT E ALT) ‚Äî ...   \n",
       "9         [7. PAR√ÇMETRO DE REDE ‚Äî APN/dados m√≥veis.]   \n",
       "\n",
       "                                 section_key  \n",
       "0                       20.envio de comandos  \n",
       "1                       20.envio de comandos  \n",
       "2                       20.envio de comandos  \n",
       "3                       20.envio de comandos  \n",
       "4                       20.envio de comandos  \n",
       "5              27.configurando fine tracking  \n",
       "6              27.configurando fine tracking  \n",
       "7              27.configurando fine tracking  \n",
       "8  24.configura√ß√£o de cabe√ßalhos (stt e alt)  \n",
       "9                        7.par√¢metro de rede  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de exemplos: 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATASET = Path(\"eval_queries.jsonl\")\n",
    "RESULTS_DIR = Path(\"eval_results\"); RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "rows = [json.loads(line) for line in DATASET.read_text(encoding=\"utf-8\").splitlines()]\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "display(df.head(10))\n",
    "print(\"Total de exemplos:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74748b5",
   "metadata": {},
   "source": [
    "# RagPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a44e2138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/api/api_manager.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import gzip\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "\n",
    "import faiss\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# RAG plumbing (optimized service uses sentence selection + compact prompts)\n",
    "from rag.config import RetrievalConfig\n",
    "from rag.pipeline import RAGPipeline\n",
    "from rag.config import RetrievalConfig, Timeouts, BuildLimits\n",
    "\n",
    "# Rerankers / LLM / embedder\n",
    "from rag.rerank.hf_cross_encoder import HFCrossEncoderLongReranker\n",
    "from rag.ollama import OllamaClient\n",
    "from rag.init import get_embedder\n",
    "\n",
    "# Tokenizer used to build/search BM25\n",
    "from rag.utils import tokenize\n",
    "\n",
    "# Retrievers\n",
    "from rag.retrievers.dense_faiss import FaissRetriever\n",
    "from rag.retrievers.sparse_bm25 import BM25Retriever\n",
    "from rag.retrievers.multiquery_hybrid import MultiQueryHybridRetriever\n",
    "from rag.query_expander import QueryExpander\n",
    "from rag.types import DocStore\n",
    "\n",
    "@staticmethod\n",
    "def _env_int(name: str, default: int) -> int:\n",
    "    try:\n",
    "        return int(os.getenv(name, default))\n",
    "    except Exception:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5c1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index (GPU if available) ----\n",
    "faiss_path = PROJECT_DIR / \"st3405_data/index/st4305_text_bgem3.faiss\"\n",
    "if not Path(faiss_path).exists():\n",
    "    raise FileNotFoundError(f\"FAISS index not found at {faiss_path}\")\n",
    "\n",
    "index = faiss.read_index(str(faiss_path))\n",
    "try:\n",
    "    if os.getenv(\"RAG_FAISS_GPU\", \"0\") == \"1\":\n",
    "        if faiss.get_num_gpus() > 0:\n",
    "            res = faiss.StandardGpuResources()\n",
    "            index = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "            index_device = \"gpu\"\n",
    "except Exception:\n",
    "    # GPU not available or FAISS GPU build not installed ‚Üí stay on CPU\n",
    "    index_device = \"cpu\"\n",
    "\n",
    "# IVF/HNSW search breadth (no-op for Flat)\n",
    "try:\n",
    "    if hasattr(index, \"nprobe\"):\n",
    "        index.nprobe = max(32, int(0.1 * getattr(index, \"nlist\", 100)))\n",
    "    if hasattr(index, \"hnsw\"):\n",
    "        index.hnsw.efSearch = int(os.getenv(\"RAG_FAISS_EFSEARCH\", \"256\"))\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Load store: docs (text), meta, ids, and stored model name ----\n",
    "store_path = PROJECT_DIR / \"st3405_data/index/st4305_store.pkl.gz\"\n",
    "if not Path(store_path).exists():\n",
    "    raise FileNotFoundError(f\"Store file not found at {store_path}\")\n",
    "\n",
    "with gzip.open(store_path, \"rb\") as f:\n",
    "    store = pickle.load(f)\n",
    "\n",
    "docs: List[str] = store[\"docs\"]\n",
    "meta: List[dict] = store[\"meta\"]\n",
    "ids:  List[str] = store[\"ids\"]\n",
    "\n",
    "embedder_model_name = store.get(\"model\", os.getenv(\"RAG_EMBEDDER_MODEL\"))\n",
    "\n",
    "assert index.ntotal == len(docs) == len(meta) == len(ids), (\n",
    "    f\"Index/store size mismatch: faiss={index.ntotal}, docs={len(docs)}, meta={len(meta)}, ids={len(ids)}\"\n",
    ")\n",
    "\n",
    "# id -> metadata/text\n",
    "id_to_meta = {ids[i]: {**meta[i], \"doc_id\": ids[i]} for i in range(len(ids))}\n",
    "doc_store: DocStore = {ids[i]: docs[i] for i in range(len(ids))}\n",
    "\n",
    "# ---- 4) Embedder (normalize=True for cosine/IP) ----\n",
    "emb_model = get_embedder(embedder_model_name, use_fp16=True, normalize=True)\n",
    "\n",
    "# ---- 5) BM25 over the docs using the SAME tokenizer ----\n",
    "tokenized = [tokenize(t) for t in docs]\n",
    "bm25 = BM25Okapi(\n",
    "    tokenized,\n",
    "    k1=float(os.getenv(\"RAG_BM25_K1\", \"1.4\")),\n",
    "    b=float(os.getenv(\"RAG_BM25_B\", \"0.4\")),\n",
    ")\n",
    "\n",
    "# ---- 6) LLM client (Ollama) ----\n",
    "ollama = OllamaClient(\n",
    "    base_url=os.getenv(\"RAG_OLLAMA_BASE_URL\", \"http://localhost:11434\"),\n",
    "    model=os.getenv(\"RAG_OLLAMA_MODEL\", \"llama3:latest\"),\n",
    "    timeout=int(os.getenv(\"RAG_OLLAMA_TIMEOUT\", \"120\")),\n",
    ")\n",
    "\n",
    "# ---- 7) Retrieval configuration ----\n",
    "cfg = RetrievalConfig(\n",
    "    query_variations=_env_int(\"RAG_QUERY_VARIATIONS\", 5),\n",
    "    dense_k_per_query=_env_int(\"RAG_DENSE_K_PER_QUERY\", 80),\n",
    "    sparse_k_per_query=_env_int(\"RAG_SPARSE_K_PER_QUERY\", 80),\n",
    "    rrf_k_const=_env_int(\"RAG_RRF_K_CONST\", 50),\n",
    "    candidate_k_for_rerank=_env_int(\"RAG_CANDIDATE_K_FOR_RERANK\", 160),\n",
    "    final_top_n=_env_int(\"RAG_FINAL_TOP_N\", 12),\n",
    ")\n",
    "\n",
    "# ---- 8) Build retriever stack (dense + sparse ‚Üí per-query hybrid ‚Üí multi-query hybrid) ----\n",
    "dense = FaissRetriever(faiss_index=index, id_map=ids, embedder=emb_model)\n",
    "sparse = BM25Retriever(bm25=bm25, id_map=ids, tokenize_fn=tokenize)\n",
    "\n",
    "use_expand = os.getenv(\"RAG_QUERY_EXPAND\", \"1\") == \"1\"\n",
    "expander = QueryExpander(llm=ollama) if use_expand else None\n",
    "\n",
    "retriever = MultiQueryHybridRetriever(\n",
    "    dense=dense,\n",
    "    sparse=sparse,\n",
    "    expander=expander,\n",
    "    rrf_k=cfg.rrf_k_const,\n",
    "    per_query_k=max(cfg.dense_k_per_query, cfg.sparse_k_per_query),\n",
    "    final_limit=cfg.candidate_k_for_rerank,\n",
    ")\n",
    "\n",
    "# ---- 10) Build the optimized RAG service ----\n",
    "\n",
    "tmo = Timeouts()          # uses env defaults\n",
    "limits = BuildLimits()    # uses env defaults\n",
    "\n",
    "rag_pipeline = RAGPipeline(\n",
    "    retriever=retriever,\n",
    "    embedder=emb_model,\n",
    "    llm=ollama,\n",
    "    doc_store=doc_store,\n",
    "    cfg=cfg,\n",
    "    tmo=tmo,\n",
    "    limits=limits,\n",
    "    meta_store=id_to_meta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40811839",
   "metadata": {},
   "source": [
    "# M√©tricas (Retrieval & Ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a70dc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def precision_at_k(relevant: set, ranked_ids: list, k: int = 5):\n",
    "    k = min(k, len(ranked_ids))\n",
    "    if k == 0: return 0.0\n",
    "    hits = sum(1 for i in range(k) if ranked_ids[i] in relevant)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(relevant: set, ranked_ids: list, k: int = 5):\n",
    "    if not relevant: return 0.0\n",
    "    k = min(k, len(ranked_ids))\n",
    "    hits = sum(1 for i in range(k) if ranked_ids[i] in relevant)\n",
    "    return hits / len(relevant)\n",
    "\n",
    "def mrr(relevant: set, ranked_ids: list):\n",
    "    for idx, rid in enumerate(ranked_ids, start=1):\n",
    "        if rid in relevant:\n",
    "            return 1.0 / idx\n",
    "    return 0.0\n",
    "\n",
    "def hit_rate_at_k(relevant: set, ranked_ids: list, k: int = 5):\n",
    "    k = min(k, len(ranked_ids))\n",
    "    return 1.0 if any(ranked_ids[i] in relevant for i in range(k)) else 0.0\n",
    "\n",
    "def dcg_at_k(gains: list, k: int):\n",
    "    return sum((gains[i] / math.log2(i+2)) for i in range(min(k, len(gains))))\n",
    "\n",
    "def ndcg_at_k(relevant_ordered: list, ranked_ids: list, k: int = 5):\n",
    "    ideal = [1.0]*len(relevant_ordered)  # bin√°rio\n",
    "    gains = [1.0 if rid in set(relevant_ordered) else 0.0 for rid in ranked_ids]\n",
    "    idcg = dcg_at_k(ideal, k)\n",
    "    if idcg == 0: return 0.0\n",
    "    return dcg_at_k(gains, k) / idcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821df15c",
   "metadata": {},
   "source": [
    "# M√©tricas (Gera√ß√£o de Texto) ‚Äî BLEU e ROUGE-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2129d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(tokens, n): \n",
    "    return list(zip(*[tokens[i:] for i in range(n)]))\n",
    "\n",
    "def bleu(candidate, reference, max_n=4):\n",
    "    cand, ref = candidate.split(), reference.split()\n",
    "    if not cand: return 0.0\n",
    "    precisions = []\n",
    "    for n in range(1, max_n+1):\n",
    "        cand_ngrams, ref_ngrams = ngrams(cand, n), ngrams(ref, n)\n",
    "        ref_counts = {ng:ref_ngrams.count(ng) for ng in ref_ngrams}\n",
    "        match = sum(min(cand_ngrams.count(ng), ref_counts.get(ng,0)) for ng in set(cand_ngrams))\n",
    "        precisions.append(match / max(1, len(cand_ngrams)))\n",
    "    bp = 1.0 if len(cand)>len(ref) else math.exp(1 - len(ref)/max(1,len(cand)))\n",
    "    gm = math.exp(sum(math.log(p) for p in precisions if p>0)/len(precisions)) if any(p>0 for p in precisions) else 0.0\n",
    "    return bp*gm\n",
    "\n",
    "def _lcs(a,b):\n",
    "    la, lb = len(a), len(b)\n",
    "    dp=[[0]*(lb+1) for _ in range(la+1)]\n",
    "    for i in range(la):\n",
    "        for j in range(lb):\n",
    "            if a[i]==b[j]: dp[i+1][j+1]=dp[i][j]+1\n",
    "            else: dp[i+1][j+1]=max(dp[i][j+1],dp[i+1][j])\n",
    "    return dp[la][lb]\n",
    "\n",
    "def rouge_l(candidate, reference):\n",
    "    cand, ref = candidate.split(), reference.split()\n",
    "    if not cand or not ref: return 0.0\n",
    "    lcs = _lcs(cand, ref)\n",
    "    prec, rec = lcs/len(cand), lcs/len(ref)\n",
    "    beta = 1.2**2\n",
    "    return ((1+beta)*prec*rec)/(rec+beta*prec) if (rec+beta*prec)>0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7818435",
   "metadata": {},
   "source": [
    "# Execu√ß√£o da Avalia√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b491307",
   "metadata": {},
   "source": [
    "# Normaliza√ß√£o e constru√ß√£o do GOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a57226a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "from typing import Dict, Iterable, List, Set\n",
    "import re\n",
    "\n",
    "def _norm_id(x: str) -> str:\n",
    "    \"\"\"Normaliza identificadores de documentos de forma agn√≥stica.\"\"\"\n",
    "    if not isinstance(x, str):\n",
    "        x = str(x)\n",
    "    return unicodedata.normalize(\"NFKC\", x).strip().lower()\n",
    "\n",
    "def normalize_ids(ids: Iterable[str]) -> List[str]:\n",
    "    \"\"\"Aplica normaliza√ß√£o a uma lista de IDs.\"\"\"\n",
    "    return [_norm_id(i) for i in ids if i is not None]\n",
    "\n",
    "def build_gold_map(row) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Constr√≥i o mapa GOLD de doc_id -> ganho (peso).\n",
    "    - Usa APENAS section_key e gold_doc_ids do dataset.\n",
    "    - Suporta opcionalmente 'gold_gains' (dict) para pesos graduados.\n",
    "    \"\"\"\n",
    "    gold_ids: Set[str] = set()\n",
    "\n",
    "    # 1) section_key (string) ‚Äî um √∫nico doc ‚Äúcorreto‚Äù principal\n",
    "    sk = row.get(\"section_key\")\n",
    "    if isinstance(sk, str) and sk.strip():\n",
    "        gold_ids.add(_norm_id(sk))\n",
    "\n",
    "    # 2) gold_doc_ids (lista) ‚Äî outros docs aceitos como corretos\n",
    "    g = row.get(\"gold_doc_ids\")\n",
    "    if isinstance(g, list):\n",
    "        for x in g:\n",
    "            if isinstance(x, str) and x.strip():\n",
    "                gold_ids.add(_norm_id(x))\n",
    "\n",
    "    # 3) Se nada foi especificado, for√ßamos corre√ß√£o do dataset (falha expl√≠cita)\n",
    "    if not gold_ids:\n",
    "        raise ValueError(\n",
    "            f\"[Dataset inv√°lido] A linha id={row.get('id')} n√£o tem 'section_key' nem 'gold_doc_ids'. \"\n",
    "            \"Preencha um dos dois para calcular m√©tricas corretamente.\"\n",
    "        )\n",
    "\n",
    "    # 4) Ganhos graduados (opcional). Se n√£o vier, tudo = 1.0 (bin√°rio).\n",
    "    gains_cfg = row.get(\"gold_gains\") or {}\n",
    "    gold_map: Dict[str, float] = {}\n",
    "    for doc_id in gold_ids:\n",
    "        gain = gains_cfg.get(doc_id, 1.0)\n",
    "        try:\n",
    "            gain = float(gain)\n",
    "        except Exception:\n",
    "            gain = 1.0\n",
    "        gold_map[doc_id] = gain\n",
    "\n",
    "    return gold_map\n",
    "\n",
    "def command_match_ratio(gold_answer: str, pred_answer: str) -> float:\n",
    "    \"\"\"\n",
    "    Retorna propor√ß√£o de comandos 'CMD;..' presentes no pred_answer.\n",
    "    Se n√£o houver comandos no gold, retorna NaN.\n",
    "    \"\"\"\n",
    "    cmds = re.findall(r\"[A-Z]{2,4};[0-9;]+\", gold_answer or \"\")\n",
    "    if not cmds:\n",
    "        return float(\"nan\")\n",
    "    pred = pred_answer or \"\"\n",
    "    hits = sum(1 for c in cmds if c in pred)\n",
    "    return hits / len(cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee01297",
   "metadata": {},
   "source": [
    "# Utilitarios para \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b78b7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Detectores + M√©tricas adaptativas para gera√ß√£o ====\n",
    "import re\n",
    "import math\n",
    "from typing import Dict, List, Tuple\n",
    "import unicodedata\n",
    "\n",
    "_CMD_RE = re.compile(r\"[A-Z]{2,4};[0-9;]+\")\n",
    "_PARAM_ID_RE = re.compile(r\"\\((\\d{3,4})\\)\")   # captura (3010), (1055), etc.\n",
    "_NUM_UNIT_RE = re.compile(\n",
    "    r\"(?P<num>(?:\\d+[.,]?\\d*))\\s*(?P<unit>mhz|dbm|v|vc{1,2}|s|ms|km/h|ma|¬µa|mah|ghz|kbps|mbps)\\b\",\n",
    "    flags=re.IGNORECASE\n",
    ")\n",
    "_BAND_RE = re.compile(r\"\\bband(as)?\\s*:?|\\b\\b(?:banda|band)\\b\", re.IGNORECASE)\n",
    "\n",
    "def _norm_txt(x: str) -> str:\n",
    "    if not isinstance(x, str): x = str(x or \"\")\n",
    "    return unicodedata.normalize(\"NFKC\", x).strip()\n",
    "\n",
    "def detect_qtype(row) -> str:\n",
    "    \"\"\"Heur√≠stica agn√≥stica baseada no GOLD (answer + hint + query).\"\"\"\n",
    "    gold = \" \".join([\n",
    "        _norm_txt(row.get(\"answer\",\"\")),\n",
    "        \" \".join(row.get(\"gold_refs_hint\", [])) if isinstance(row.get(\"gold_refs_hint\"), list) else _norm_txt(row.get(\"gold_refs_hint\",\"\")),\n",
    "        _norm_txt(row.get(\"query\",\"\"))\n",
    "    ])\n",
    "    if _CMD_RE.search(gold) or re.search(r\"\\b(reboot|reqimsi|reqver|enable\\d|disable\\d|preset|initmsgno)\\b\", gold, re.I):\n",
    "        return \"command\"\n",
    "    if _PARAM_ID_RE.search(gold) or re.search(r\"\\b(apn|porta|cabe√ßalho|stt|table|perfil)\\b\", gold, re.I):\n",
    "        return \"config\"\n",
    "    if _NUM_UNIT_RE.search(gold) or _BAND_RE.search(gold) or re.search(r\"\\bmhz|dbm|vcc|v\\b\", gold, re.I):\n",
    "        return \"specs\"\n",
    "    # fallback sem penalizar\n",
    "    return \"general\"\n",
    "\n",
    "def extract_cmds(text: str) -> List[str]:\n",
    "    return _CMD_RE.findall(text or \"\")\n",
    "\n",
    "def command_match_ratio(gold_answer: str, pred_answer: str) -> float:\n",
    "    g = extract_cmds(gold_answer); \n",
    "    if not g: return float(\"nan\")\n",
    "    hits = sum(1 for c in g if c in (pred_answer or \"\"))\n",
    "    return hits/len(g)\n",
    "\n",
    "def command_exact_match(gold_answer: str, pred_answer: str) -> float:\n",
    "    g, p = set(extract_cmds(gold_answer)), set(extract_cmds(pred_answer))\n",
    "    if not g: return float(\"nan\")\n",
    "    return 1.0 if p.issuperset(g) else 0.0\n",
    "\n",
    "def command_jaccard(gold_answer: str, pred_answer: str) -> float:\n",
    "    g, p = set(extract_cmds(gold_answer)), set(extract_cmds(pred_answer))\n",
    "    if not g and not p: return float(\"nan\")\n",
    "    inter = len(g & p); uni = len(g | p)\n",
    "    return (inter/uni) if uni else float(\"nan\")\n",
    "\n",
    "def extract_numbers_units(text: str) -> List[Tuple[str,str]]:\n",
    "    \"\"\"Retorna lista de (numero_normalizado, unidade_normalizada).\"\"\"\n",
    "    res = []\n",
    "    for m in _NUM_UNIT_RE.finditer(text or \"\"):\n",
    "        num = m.group(\"num\").replace(\",\", \".\")\n",
    "        unit = m.group(\"unit\").lower()\n",
    "        res.append((num, unit))\n",
    "    return res\n",
    "\n",
    "def numeric_unit_match(gold_answer: str, pred_answer: str) -> float:\n",
    "    \"\"\"Propor√ß√£o de (n√∫mero,unidade) do GOLD presentes no pred (como substring).\"\"\"\n",
    "    gold_pairs = extract_numbers_units(gold_answer)\n",
    "    if not gold_pairs: \n",
    "        return float(\"nan\")\n",
    "    pred = (pred_answer or \"\").lower()\n",
    "    hits = 0\n",
    "    for num, unit in gold_pairs:\n",
    "        if (num.lower() in pred) and (unit.lower() in pred):\n",
    "            hits += 1\n",
    "    return hits/len(gold_pairs)\n",
    "\n",
    "def list_overlap_ratio(gold_items: List[str], pred_text: str) -> float:\n",
    "    \"\"\"Checa a presen√ßa de cada item (ex.: bandas LTE) no texto predito (case-insensitive).\"\"\"\n",
    "    if not gold_items:\n",
    "        return float(\"nan\")\n",
    "    pred = (pred_text or \"\").lower()\n",
    "    hits = sum(1 for it in gold_items if _norm_txt(it).lower() in pred)\n",
    "    return hits/len(gold_items)\n",
    "\n",
    "def bands_from_text(text: str) -> List[str]:\n",
    "    \"\"\"Extrai bandas do tipo '1 [2100MHz], 3 [1800MHz], 5 [850MHz], 28 [700MHz]' como lista '1','3','5','28'.\"\"\"\n",
    "    if not isinstance(text, str): return []\n",
    "    bands = re.findall(r\"\\b(\\d{1,2})\\s*\\[\\s*\\d+\\s*mhz\\s*\\]\", text, flags=re.I)\n",
    "    if bands:\n",
    "        return bands\n",
    "    # fallback: s√≥ n√∫meros isolados precedidos de 'banda'/'band'\n",
    "    if _BAND_RE.search(text or \"\"):\n",
    "        bands = re.findall(r\"\\b(\\d{1,2})\\b\", text)\n",
    "    return bands\n",
    "\n",
    "def compute_generation_metrics(row, pred_answer: str) -> Dict[str, float]:\n",
    "    \"\"\"Retorna m√©tricas adequadas ao tipo detectado. NaN quando n√£o aplic√°vel.\"\"\"\n",
    "    gold_answer = _norm_txt(row.get(\"answer\",\"\"))\n",
    "    qtype = detect_qtype(row)\n",
    "    out = {\"gen_type\": qtype}\n",
    "\n",
    "    # if qtype == \"command\":\n",
    "    #     out[\"cmd_match\"]   = command_match_ratio(gold_answer, pred_answer)\n",
    "    #     out[\"cmd_exact\"]   = command_exact_match(gold_answer, pred_answer)\n",
    "    #     out[\"cmd_jaccard\"] = command_jaccard(gold_answer, pred_answer)\n",
    "    #     # BLEU/ROUGE se quiser manter:\n",
    "    #     out[\"bleu\"]    = bleu(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    #     out[\"rouge_l\"] = rouge_l(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    #     return out\n",
    "\n",
    "    # if qtype == \"config\":\n",
    "    #     out[\"num_unit_match\"] = numeric_unit_match(gold_answer, pred_answer)\n",
    "    #     # checagem de presen√ßa de IDs de par√¢metros (3010 etc.)\n",
    "    #     gold_pids = set(_PARAM_ID_RE.findall(gold_answer))\n",
    "    #     if gold_pids:\n",
    "    #         hits = sum(1 for pid in gold_pids if f\"({pid})\" in (pred_answer or \"\"))\n",
    "    #         out[\"param_id_cover\"] = hits/len(gold_pids)\n",
    "    #     else:\n",
    "    #         out[\"param_id_cover\"] = float(\"nan\")\n",
    "    #     out[\"bleu\"]    = bleu(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    #     out[\"rouge_l\"] = rouge_l(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    #     return out\n",
    "\n",
    "    # if qtype == \"specs\":        \n",
    "    #     out[\"bleu\"]    = bleu(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    #     out[\"rouge_l\"] = rouge_l(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    #     return out\n",
    "\n",
    "    # general\n",
    "    out[\"bleu\"]    = bleu(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "    out[\"rouge_l\"] = rouge_l(pred_answer, gold_answer) if gold_answer.strip() else float(\"nan\")\n",
    "\n",
    "    return out\n",
    "\n",
    "def safe_bertscore(hyp: str, ref: str, lang: str = \"pt\"):\n",
    "    from bert_score import score as bertscore_score\n",
    "    \"\"\"\n",
    "    Retorna (P, R, F1) como floats ou (None, None, None) se indispon√≠vel.\n",
    "    \"\"\"\n",
    "    hyp = hyp or \"\"\n",
    "    ref = ref or \"\"\n",
    "    try:\n",
    "        P, R, F1 = bertscore_score(\n",
    "            [hyp], [ref],\n",
    "            lang=lang,\n",
    "            rescale_with_baseline=True,\n",
    "            batch_size=8,\n",
    "            device=\"cpu\",\n",
    "        )\n",
    "        # tensores -> float\n",
    "        return float(P.mean()), float(R.mean()), float(F1.mean())\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erro ao calcular BERTScore: {e}\")\n",
    "        return None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42844aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.setdefault(\"RAG_LOG_ENABLED\",\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42609c34",
   "metadata": {},
   "source": [
    "# Avaliacao das metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aecb73ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q01: Qual o comando para reiniciar o dispositivo via envio de comandos?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4144.57it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.16it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7476.48it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.37it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7839.82it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.48it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7612.17it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q02: Qual o comando para habilitar a Sa√≠da 1?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4124.19it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.50it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7449.92it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.12it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6909.89it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.20it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5714.31it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q03: Como consultar a vers√£o do firmware do rastreador por comando?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4152.78it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.70it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7182.03it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.67it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6786.90it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.73it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5090.17it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q04: Como iniciar a calibra√ß√£o DPA por comando?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3711.77it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.83it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7145.32it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.53it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7332.70it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.69it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7543.71it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q05: Existe comando para consultar o status do antifurto?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4815.50it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.71it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4505.16it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.02it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6732.43it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.12it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6955.73it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q06: Como habilitar o Fine Tracking no ST4305?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5282.50it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.83it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7463.17it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.57it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8719.97it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.35it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6909.89it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q07: Qual par√¢metro define o intervalo entre posi√ß√µes GPS no Fine Tracking?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3347.41it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.71it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6543.38it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.78it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8305.55it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.26it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6864.65it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q08: Como definir a quantidade de posi√ß√µes enviadas por relat√≥rio no Fine Tracking?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4064.25it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.21it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6462.72it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.28it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7294.44it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.66it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5518.82it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q09: Quais campos podem ser habilitados no cabe√ßalho STT (Small Table)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4136.39it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.09it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6700.17it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.99it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6921.29it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.54it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8305.55it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q10: Como configurar a APN de dados (par√¢metros de rede)?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3063.77it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.33it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6452.78it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.14it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8112.77it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.79it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7145.32it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q11: Como configurar ou desabilitar a senha de acesso no Synctrak?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3960.63it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.24it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5652.70it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.36it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5203.85it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.13it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6864.65it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q12: Como adicionar o ID do motorista usando 1-Wire?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3792.32it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.82it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5629.94it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.79it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6061.13it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.65it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6472.69it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  9.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q13: Como remover um ID do motorista previamente cadastrado?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4401.16it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.88it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4798.97it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.76it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6241.52it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.11it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6492.73it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q14: Como ler (identificar) o ID do motorista presente no ve√≠culo?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4350.94it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.45it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5275.85it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.91it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7037.42it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.22it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6132.02it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q15: Onde verificar o status do GPS/WWAN e do cart√£o SIM para diagn√≥stico?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4190.11it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.85it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5210.32it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.86it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7584.64it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.94it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5216.80it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q16: Quais bandas de 2G e LTE s√£o suportadas pelo ST4305/ST8300?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3423.92it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.50it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4987.28it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.53it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7332.70it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.72it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5223.29it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q17: Qual √© a faixa de temperatura de opera√ß√£o do equipamento?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3269.14it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.07it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4609.13it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.02it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8272.79it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.54it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6605.20it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q18: Qual √© a tens√£o de alimenta√ß√£o principal suportada?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3344.74it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.04it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6034.97it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.84it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8097.11it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.23it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 8793.09it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q19: Qual a capacidade de mem√≥ria FIFO de posi√ß√µes?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 4284.27it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.86it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6355.01it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.05it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6932.73it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.05it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7530.17it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Pergunta Q20: O produto √© homologado por algum √≥rg√£o regulat√≥rio?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 3685.68it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.82it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 6853.44it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  7.57it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 5793.24it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 11.58it/s]\n",
      "pre tokenize: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 7958.83it/s]\n",
      "Inference Embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Resultados salvos em: eval_results/rag_pipeline_results.jsonl\n",
      "‚è±Ô∏è Lat√™ncia m√©dia (s/query): 17.175\n",
      "üß™ Linhas avaliadas: 20\n"
     ]
    }
   ],
   "source": [
    "# ==== Execu√ß√£o (N quest√µes) + m√©tricas (inclui BERTScore) + salvamento em JSONL ====\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "K_LIST = [1, 3, 5]\n",
    "records, latencies = [], []\n",
    "\n",
    "RESULTS_DIR = RESULTS_DIR\n",
    "res_path = RESULTS_DIR / \"rag_pipeline_results.jsonl\"\n",
    "\n",
    "\n",
    "# Limpa arquivo anterior (opcional)\n",
    "if res_path.exists():\n",
    "    res_path.unlink()\n",
    "\n",
    "rows_iter = df.iterrows()  # ex.: df.iterrows() para todas\n",
    "\n",
    "for i, row in rows_iter:\n",
    "    qid         = row[\"id\"]\n",
    "    query       = row[\"query\"]\n",
    "    gold_answer = row.get(\"answer\", \"\") or \"\"\n",
    "\n",
    "    print(f\"\\nüîç Pergunta {qid}: {query}\")\n",
    "\n",
    "    # Execu√ß√£o do pipeline (end-to-end)\n",
    "    t0 = time.time()\n",
    "    result = rag_pipeline.answer(query)\n",
    "    t1 = time.time()\n",
    "    lat = t1 - t0\n",
    "    latencies.append(lat)\n",
    "\n",
    "    # Resposta e docs retornados pelo pipeline\n",
    "    answer          = (result.get(\"answer\") or \"\").strip()\n",
    "    ranked_ids_raw  = result.get(\"docs\", []) or []\n",
    "    ranked_ids      = normalize_ids(ranked_ids_raw)   # <<< sua normaliza√ß√£o\n",
    "    top1_score      = float(result.get(\"score_top1\", 0.0) or 0.0)\n",
    "\n",
    "    #print(f\"\\nüß† Resposta gerada:\\n{answer}\\n\")\n",
    "    #print(f\"üìÑ Docs recuperados: {ranked_ids}\")\n",
    "\n",
    "    # === GOLD determin√≠stico (sem heur√≠stica/df_docs) ===\n",
    "    gold_map = build_gold_map(row)     # dict: doc_id_normalizado -> ganho\n",
    "    relevant = set(gold_map.keys())    # conjunto para m√©tricas bin√°rias\n",
    "\n",
    "    # === M√©tricas de retrieval ===\n",
    "    rec = {\n",
    "        \"id\": qid,\n",
    "        \"category\": row.get(\"category\", \"\"),\n",
    "        **{f\"precision@{k}\": precision_at_k(relevant, ranked_ids, k) for k in K_LIST},\n",
    "        **{f\"recall@{k}\":    recall_at_k(relevant,  ranked_ids, k) for k in K_LIST},\n",
    "        \"mrr\": mrr(relevant, ranked_ids),\n",
    "        **{f\"hit@{k}\":  hit_rate_at_k(relevant, ranked_ids, k) for k in K_LIST},\n",
    "        **{f\"ndcg@{k}\": ndcg_at_k(list(relevant), ranked_ids, k) for k in K_LIST},\n",
    "    }\n",
    "\n",
    "    # === M√©tricas de gera√ß√£o existentes (ex.: BLEU/ROUGE) ===\n",
    "    genm = compute_generation_metrics(row, answer)  # mant√©m sua fun√ß√£o atual\n",
    "    rec.update(genm)\n",
    "\n",
    "    # === BERTScore (P/R/F1) por quest√£o ===\n",
    "    bsP, bsR, bsF1 = safe_bertscore(answer, gold_answer, lang=\"pt\")\n",
    "    rec[\"bertscore_P\"]  = bsP\n",
    "    rec[\"bertscore_R\"]  = bsR\n",
    "    rec[\"bertscore_F1\"] = bsF1\n",
    "\n",
    "    # Extras √∫teis para auditoria\n",
    "    rec[\"gen_answer\"]     = answer\n",
    "    rec[\"gold_answer\"]    = gold_answer\n",
    "    rec[\"score_top1\"]     = top1_score\n",
    "    rec[\"docs\"]           = ranked_ids\n",
    "    rec[\"latency_sec\"]    = lat\n",
    "    rec[\"gold_refs_hint\"] = row[\"gold_refs_hint\"] if \"gold_refs_hint\" in row else \"\"\n",
    "\n",
    "    records.append(rec)\n",
    "\n",
    "# Tabela consolidada\n",
    "records_df = pd.DataFrame(records)\n",
    "\n",
    "# Salvar JSONL\n",
    "with res_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for r in records:\n",
    "        json.dump(r, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# Sum√°rio r√°pido\n",
    "avg_latency = (sum(latencies) / len(latencies)) if latencies else float(\"nan\")\n",
    "print(f\"\\n‚úÖ Resultados salvos em: {res_path}\")\n",
    "print(f\"‚è±Ô∏è Lat√™ncia m√©dia (s/query): {avg_latency:.3f}\")\n",
    "print(f\"üß™ Linhas avaliadas: {len(records_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd0ea12",
   "metadata": {},
   "source": [
    "# Sum√°rios (Global e por Categoria) em .jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259193fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ summary_global.jsonl ‚Üí eval_results/summary_global.jsonl\n",
      "‚úÖ summary_by_category.jsonl ‚Üí eval_results/summary_by_category.jsonl\n"
     ]
    }
   ],
   "source": [
    "# ==== Sum√°rios Global e por Categoria em JSONL ====\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "DEC = 3 \n",
    "\n",
    "res_path = RESULTS_DIR / \"rag_pipeline_results.jsonl\"\n",
    "sum_cat_path = RESULTS_DIR / \"summary_by_category.jsonl\"\n",
    "sum_glb_path = RESULTS_DIR / \"summary_global.jsonl\"\n",
    "\n",
    "# Carrega o JSONL recem-salvo\n",
    "pred = [json.loads(l) for l in res_path.read_text(encoding=\"utf-8\").splitlines() if l.strip()]\n",
    "df_pred = pd.DataFrame(pred)\n",
    "\n",
    "agg_cols = [c for c in [\n",
    "    \"precision@1\",\"precision@3\",\"precision@5\",\n",
    "    \"recall@1\",\"recall@3\",\"recall@5\",\n",
    "    \"mrr\",\"hit@1\",\"hit@3\",\"hit@5\",\n",
    "    \"ndcg@1\",\"ndcg@3\",\"ndcg@5\",\n",
    "    \"bleu\",\"rouge_l\",\n",
    "    \"bertscore_P\",\"bertscore_R\",\"bertscore_F1\",\n",
    "] if c in df_pred.columns]\n",
    "\n",
    "# Global\n",
    "summary_global = df_pred[agg_cols].mean(numeric_only=True).to_frame(\"mean\").reset_index().rename(columns={\"index\":\"metric\"})\n",
    "summary_global[\"mean\"] = summary_global[\"mean\"].round(DEC)\n",
    "\n",
    "# Por categoria (se houver)\n",
    "cat_col = \"category\" if \"category\" in df_pred.columns else None\n",
    "if cat_col:\n",
    "    summary_by_cat = df_pred.groupby(cat_col)[agg_cols].mean(numeric_only=True).reset_index()\n",
    "    summary_by_cat[agg_cols] = summary_by_cat[agg_cols].round(DEC)\n",
    "else:\n",
    "    summary_by_cat = pd.DataFrame()\n",
    "\n",
    "# Salvar como JSONL\n",
    "with sum_glb_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in summary_global.iterrows():\n",
    "        json.dump(row.to_dict(), f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "with sum_cat_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in summary_by_cat.iterrows():\n",
    "        json.dump(row.to_dict(), f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"‚úÖ summary_global.jsonl ‚Üí {sum_glb_path}\")\n",
    "print(f\"‚úÖ summary_by_category.jsonl ‚Üí {sum_cat_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st4305rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

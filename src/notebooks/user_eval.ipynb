{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581c121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def get_root_path():\n",
    "    \"\"\"Always use the same, absolute (relative to root) paths\n",
    "\n",
    "    which makes moving the notebooks around easier.\n",
    "    \"\"\"\n",
    "    return Path(os.getcwd()).parent\n",
    "\n",
    "PROJECT_DIR = Path(get_root_path())\n",
    "assert PROJECT_DIR.exists(), PROJECT_DIR\n",
    "\n",
    "if str(PROJECT_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_DIR))\n",
    "\n",
    "print(\"Using project at:\", PROJECT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Merge eval_queries.jsonl and rag_pipeline_results.jsonl into a single dataset.\n",
    "- Keeps columns: id, category, query, answer, section_key from eval set\n",
    "- Adds gen_answer from results (left join on id by default; falls back to query if requested/needed)\n",
    "- Adds empty columns: Clareza, Precisão, Utilidade\n",
    "- Saves CSV and (if available) Parquet\n",
    "Usage:\n",
    "    python merge_eval_results.py \\\n",
    "        --eval /path/to/eval_queries.jsonl \\\n",
    "        --results /path/to/rag_pipeline_results.jsonl \\\n",
    "        --out /path/to/output.csv \\\n",
    "        [--merge-on auto|id|query]\n",
    "\"\"\"\n",
    "import argparse\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "REQUIRED_EVAL_COLS = [\"id\", \"category\", \"query\", \"answer\", \"section_key\"]\n",
    "SCORE_COLS = [\"Clareza\\n1 - 5\", \"Precisão\\n1 - 5\", \"Utilidade\\n1 - 5\"]\n",
    "\n",
    "def read_jsonl(path: Path) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    try:\n",
    "        return pd.read_json(path, lines=True)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Failed to parse JSONL at {path}: {e}\")\n",
    "\n",
    "def main():\n",
    "    \n",
    "    eval_df = read_jsonl(PROJECT_DIR / \"notebooks/eval_queries.jsonl\")\n",
    "    res_df = read_jsonl(PROJECT_DIR / \"notebooks/eval_results/v2/rag_pipeline_results.jsonl\")\n",
    "\n",
    "    # Validate eval columns\n",
    "    missing_eval = [c for c in REQUIRED_EVAL_COLS if c not in eval_df.columns]\n",
    "    if missing_eval:\n",
    "        raise SystemExit(f\"Missing required columns in eval_queries: {missing_eval}\")\n",
    "\n",
    "    # Determine merge key\n",
    "    merge_key = \"id\"\n",
    "\n",
    "    # Ensure gen_answer exists\n",
    "    if \"gen_answer\" not in res_df.columns:\n",
    "        res_df[\"gen_answer\"] = None\n",
    "\n",
    "    # Build a slim results frame\n",
    "    res_keep = res_df[[merge_key, \"gen_answer\"]].copy()\n",
    "\n",
    "    # Perform left join\n",
    "    merged = pd.merge(\n",
    "        eval_df[REQUIRED_EVAL_COLS].copy(),\n",
    "        res_keep,\n",
    "        how=\"left\",\n",
    "        left_on=merge_key,\n",
    "        right_on=merge_key,\n",
    "        suffixes=(\"\", \"_res\"),\n",
    "    )\n",
    "\n",
    "    # Add scoring columns\n",
    "    for col in SCORE_COLS:\n",
    "        if col not in merged.columns:\n",
    "            merged[col] = \"\"\n",
    "\n",
    "    # Determine output path\n",
    "    \n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_path = PROJECT_DIR / f\"notebooks/eval_with_results_{ts}.csv\"\n",
    "\n",
    "    # Save CSV\n",
    "    merged.to_csv(out_path, index=False)\n",
    "\n",
    "\n",
    "    # Summary\n",
    "    print(\"✅ Merge completed\")\n",
    "    print(f\" • rows: {len(merged):,}\")\n",
    "    print(f\" • cols: {len(merged.columns):,} -> {list(merged.columns)}\")\n",
    "    print(f\" • CSV: {out_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "st4305rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
